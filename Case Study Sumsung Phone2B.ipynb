{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9295e6e4",
   "metadata": {},
   "source": [
    "# Build a Python web scraper with Beautiful Soup\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d961d70f",
   "metadata": {},
   "source": [
    "# What’s web scraping?\n",
    "-Web scraping is a technique used to collect data from the internet. Web scrapers are programmed to go to websites, get the relevant pages and extract the information needed. The automation of this process allows tons of data to be extracted at a high speed.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46da1ae9",
   "metadata": {},
   "source": [
    "# Scraping data from 2b website\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "594101b9",
   "metadata": {},
   "source": [
    "In this tutorial, we will build a web scraper using the libraries Beautiful Soup and Requests in Python to extract the following data from 2b website.\n",
    "\n",
    "· Product Type\n",
    "\n",
    "· Product Price\n",
    "\n",
    "· Product Rating\n",
    "\n",
    "Let's Goooooo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bffc1196",
   "metadata": {},
   "source": [
    "# Case study : 2b Samsung Phone\n",
    "URL :https://2b.com.eg/en/catalogsearch/result/?q=sumsung How Do you scrape Data From ex website ?\n",
    "\n",
    "1- find The URL that you want to scrape\n",
    "\n",
    "2- inspecting the page\n",
    "\n",
    "3- find the data you want to extract\n",
    "\n",
    "4- Write the code 5-run and extract\n",
    "\n",
    "6-export the data in the required format"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eacf772c",
   "metadata": {},
   "source": [
    "# importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77db1211",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "505ab928",
   "metadata": {},
   "source": [
    "# import libraries & methods "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3b7af01",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install bs4 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf81be52",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup as bs #for Scrapping "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0665d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen #for Connection (open )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e80b08d",
   "metadata": {},
   "source": [
    "\n",
    "# import URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2c84779",
   "metadata": {},
   "outputs": [],
   "source": [
    "url =\"https://2b.com.eg/en/catalogsearch/result/?q=samsung\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "339a9bbe",
   "metadata": {},
   "source": [
    "\n",
    "# Create a client - based request to get the request (open con.)\n",
    "\n",
    "We start by downloading the pages using the method get in the Python requests library. It sends a request to the specified URL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "316f7ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = urlopen(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bbfcc87",
   "metadata": {},
   "source": [
    " So our request is not denied."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaaf0d82",
   "metadata": {},
   "source": [
    "# Getting HTML code of the full website\n",
    "\n",
    "Once the request was successful, we want to convert it into a code using .read(). The output is a huge mess, HTML content that we cannot make sense of. That’s when Beautiful Soup Python library comes into play."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21df8a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "page = client.read() #to read html code "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1fa8e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "#page "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5487572",
   "metadata": {},
   "outputs": [],
   "source": [
    "client.close () #for closing html code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f2c25cd",
   "metadata": {},
   "source": [
    "\n",
    "# Creating an HTML parser using bs.soup\n",
    "\n",
    "Beautiful Soup is a Python library for parsing structured data. \n",
    "\n",
    "When you add the last line of code, a Beautiful Soup object is created. It takes page.text, which is the HTML content you scraped earlier, as its input. The second argument, “html.parser”, makes sure that you use the right parser for HTML content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8cded62",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = bs (page,\"html\") # kind of parser = html\n",
    "#soup is container "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1833a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "#soup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55236823",
   "metadata": {},
   "source": [
    "\n",
    "# Before we go any further let’s look at the Beautiful Soup Functions used in this tutorial.\n",
    "\n",
    "find_all — returns a list containing all results matching the search criteria defined.\n",
    "\n",
    "find — returns the first result matching a search criterion that we applied on a Beautiful Soup object.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf4dff68",
   "metadata": {},
   "source": [
    "# Creating a container For target Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9a7b9a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "container = soup.find_all ('div',{'class':\"product details product-item-details\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "585179c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "container[0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bb7c1c4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "len (container)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d26a6df",
   "metadata": {},
   "source": [
    "# Extracting product type and price details\n",
    "\n",
    "\n",
    "Clicking on inspect product type reveals the following code. we can either use the find method passing the tag <a> class=”product-item-link”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5280241",
   "metadata": {},
   "outputs": [],
   "source": [
    "item_name = soup.find_all ('a',{'class':'product-item-link'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd84a41d",
   "metadata": {},
   "outputs": [],
   "source": [
    "item_name [0].text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2988e40c",
   "metadata": {},
   "outputs": [],
   "source": [
    "item_rating = soup.find_all ('div',{'class':'rating-result'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e312bbc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "item_rating[0].text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eba04941",
   "metadata": {},
   "outputs": [],
   "source": [
    "item_price = soup.find_all('span',{'class':'price-wrapper'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f216aa40",
   "metadata": {},
   "outputs": [],
   "source": [
    "item_price[0].text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f62f1da6",
   "metadata": {},
   "source": [
    "# compine it together\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4493dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open (\"Desktop/case_study/2b_samsung.csv\",\"w\")\n",
    "header = 'item_name,item_rating,item_price \\n'\n",
    "file.write(header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02fb6b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for looping multible pages\n",
    "for j in range (1,7) :\n",
    "    url= f'https://2b.com.eg/en/catalogsearch/result?p={j}&q=samsung+' #f= format \n",
    "    res=requests.get(url)\n",
    "    soup=bs(res.text)\n",
    "    container = soup.find_all ('div',{'class':\"product details product-item-details\"})\n",
    "    for i in container :\n",
    "        item_name = i.find_all ('a',{'class':'product-item-link'})\n",
    "        item_name =item_name [0].text.strip()\n",
    "        item_rating = i.find_all ('div',{'class':'rating-result'})\n",
    "        item_rating = item_rating[0].text.strip()\n",
    "        item_price = i.find_all('div',{'class':'price-box'})\n",
    "        item_price =item_price[0].text.strip().replace (\"\\n\",\" \").replace(\",\",\"\")\n",
    "        file.write(item_name+\" , \"+item_rating+\" , \"+item_price +\"\\n\")\n",
    "        print(item_name+\" , \"+item_rating+\" , \"+item_price)\n",
    "        print( )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "141ba0bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#note : the price is incorrect :)))))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01870c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "#now we can import data as CSV file :))))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35b46b33",
   "metadata": {},
   "source": [
    "# Thank you \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0ba6251",
   "metadata": {},
   "outputs": [],
   "source": [
    "#finally we must close file connection "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0dad65f",
   "metadata": {},
   "outputs": [],
   "source": [
    "file.close ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f1015a7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
